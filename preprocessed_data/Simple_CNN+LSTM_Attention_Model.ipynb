{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Simple_CNN+LSTM_Model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbyeYXOM8-mD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "from PIL import Image\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import torch.optim as optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAOoR7hnii2R",
        "colab_type": "code",
        "outputId": "7c82f89e-04e2-4f43-e58e-0c5539396b28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "!unzip preprocessed_data.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  preprocessed_data.zip\n",
            "   creating: preprocessed_data/\n",
            "  inflating: preprocessed_data/train_questions.npy  \n",
            "  inflating: preprocessed_data/val_questions.npy  \n",
            "  inflating: preprocessed_data/train_image_features.npy  \n",
            "  inflating: preprocessed_data/answer_tokens_top1k.json  \n",
            "  inflating: preprocessed_data/val_dataset_1k.json  \n",
            "  inflating: preprocessed_data/val_dataset_1k_tokenised.json  \n",
            "  inflating: preprocessed_data/combined_val_input.npy  \n",
            "  inflating: preprocessed_data/val_image_features.npy  \n",
            "  inflating: preprocessed_data/train_dataset_5k.json  \n",
            "  inflating: preprocessed_data/train_dataset_5k_tokenised.json  \n",
            "   creating: preprocessed_data/.ipynb_checkpoints/\n",
            "  inflating: preprocessed_data/.ipynb_checkpoints/Simple_CNN+LSTM_Model-checkpoint.ipynb  \n",
            "  inflating: preprocessed_data/val_answers.npy  \n",
            "  inflating: preprocessed_data/train_answers.npy  \n",
            "   creating: preprocessed_data/6B.50.dat/\n",
            "  inflating: preprocessed_data/6B.50.dat/__attrs__  \n",
            "   creating: preprocessed_data/6B.50.dat/meta/\n",
            "  inflating: preprocessed_data/6B.50.dat/meta/storage  \n",
            "  inflating: preprocessed_data/6B.50.dat/meta/sizes  \n",
            "   creating: preprocessed_data/6B.50.dat/data/\n",
            "  inflating: preprocessed_data/6B.50.dat/data/__0.blp  \n",
            "  inflating: preprocessed_data/Simple_CNN+LSTM_Model.ipynb  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0qkuaXCqPuLw",
        "outputId": "bdd4c6d5-a516-43af-a897-de5c23b615f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "!wget http://nlp.stanford.edu/data/wordvecs/glove.6B.zip"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-02 15:06:08--  http://nlp.stanford.edu/data/wordvecs/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/wordvecs/glove.6B.zip [following]\n",
            "--2020-04-02 15:06:08--  https://nlp.stanford.edu/data/wordvecs/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/wordvecs/glove.6B.zip [following]\n",
            "--2020-04-02 15:06:08--  http://downloads.cs.stanford.edu/nlp/data/wordvecs/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182753 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  2.05MB/s    in 6m 28s  \n",
            "\n",
            "2020-04-02 15:12:36 (2.12 MB/s) - ‘glove.6B.zip’ saved [862182753/862182753]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TMXJm9B4P3NK",
        "outputId": "637c4e0e-01ae-4293-ff4e-3395c273c47a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "!unzip glove.6B.zip"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n",
            "  inflating: glove.6B.50d.txt        \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o9BVTM74Tkdl",
        "outputId": "9335bc8b-84c1-400e-eaf0-fa06fde59df3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "!pip install bcolz"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bcolz\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/4e/23942de9d5c0fb16f10335fa83e52b431bcb8c0d4a8419c9ac206268c279/bcolz-1.2.1.tar.gz (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 4.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from bcolz) (1.18.2)\n",
            "Building wheels for collected packages: bcolz\n",
            "  Building wheel for bcolz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bcolz: filename=bcolz-1.2.1-cp36-cp36m-linux_x86_64.whl size=2666373 sha256=5f924732a4f7ed7a0a383235c4ce8684d97d4db550c6bdb560a4a4a0d690e0a2\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/78/26/fb8c0acb91a100dc8914bf236c4eaa4b207cb876893c40b745\n",
            "Successfully built bcolz\n",
            "Installing collected packages: bcolz\n",
            "Successfully installed bcolz-1.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RaZyEyAgzxlY",
        "colab_type": "code",
        "outputId": "9e481840-a84d-4ad1-f579-b1d3332a367f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "image_features_train = np.load(\"preprocessed_data/train_image_features.npy\")\n",
        "questions_train = np.load(\"preprocessed_data/train_questions.npy\")\n",
        "answers_train = np.load(\"preprocessed_data/train_answers.npy\")\n",
        "print(image_features_train.shape)\n",
        "print(questions_train.shape)\n",
        "print(answers_train.shape)\n",
        "\n",
        "image_features_val = np.load(\"preprocessed_data/val_image_features.npy\")\n",
        "questions_val = np.load(\"preprocessed_data/val_questions.npy\")\n",
        "answers_val = np.load(\"preprocessed_data/val_answers.npy\")\n",
        "print(image_features_val.shape)\n",
        "print(questions_val.shape)\n",
        "print(answers_val.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4269, 512)\n",
            "(4269, 25)\n",
            "(4269, 1)\n",
            "(837, 512)\n",
            "(837, 25)\n",
            "(837, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OjibYVw2R24K",
        "outputId": "64d4aa75-8900-42c9-e1a6-3d9a83e3e3e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import bcolz\n",
        "import pickle\n",
        "\n",
        "words = []\n",
        "idx = 0\n",
        "word2idx = {}\n",
        "glove_path = \"\"\n",
        "vectors = bcolz.carray(np.zeros(1), rootdir=f'6B.50.dat', mode='w')\n",
        "\n",
        "with open(f'glove.6B.300d.txt', 'rb') as f:\n",
        "    for l in f:\n",
        "        line = l.decode().split()\n",
        "        word = line[0]\n",
        "        words.append(word)\n",
        "        word2idx[word] = idx\n",
        "        idx += 1\n",
        "        vect = np.array(line[1:]).astype(np.float)\n",
        "        vectors.append(vect)\n",
        "\n",
        "print(vectors.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(120000301,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "de_bAkvuw9jc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vectors = bcolz.carray(vectors[1:].reshape((400001, 300)), rootdir=f'6B.300.dat', mode='w')\n",
        "vectors.flush()\n",
        "pickle.dump(words, open(f'6B.300_words.pkl', 'wb'))\n",
        "pickle.dump(word2idx, open(f'6B.300_idx.pkl', 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dpQCqBu2TjUn",
        "colab": {}
      },
      "source": [
        "import bcolz\n",
        "import pickle \n",
        "\n",
        "vectors = bcolz.open(f'6B.300.dat')[:]\n",
        "words = pickle.load(open(f'6B.300_words.pkl', 'rb'))\n",
        "word2idx = pickle.load(open(f'6B.300_idx.pkl', 'rb'))\n",
        "\n",
        "glove = {w: vectors[word2idx[w]] for w in words}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CRCCTMrp0NpK",
        "outputId": "85c94e1d-f5df-4993-bc2c-357e033f6054",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "matrix_len = 400001\n",
        "weights_matrix = np.zeros((matrix_len, 300))\n",
        "words_found = 0\n",
        "\n",
        "for i, word in enumerate(glove.keys()):\n",
        "    try: \n",
        "        weights_matrix[i] = glove[word]\n",
        "        words_found += 1\n",
        "    except KeyError:\n",
        "        weights_matrix[i] = np.random.normal(scale=0.6, size=(emb_dim, ))\n",
        "\n",
        "weights_matrix=torch.from_numpy(weights_matrix)\n",
        "print(weights_matrix.size())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([400001, 300])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Cu05PnLw_Vcb",
        "colab": {}
      },
      "source": [
        "def create_emb_layer(weights_matrix, non_trainable=False):\n",
        "    num_embeddings, embedding_dim = weights_matrix.size()\n",
        "    emb_layer = nn.Embedding(num_embeddings, embedding_dim)\n",
        "    emb_layer.load_state_dict({'weight': weights_matrix})\n",
        "    if non_trainable:\n",
        "        emb_layer.weight.requires_grad = False\n",
        "\n",
        "    return emb_layer, num_embeddings, embedding_dim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vDtXe4doMKQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AttentionNetwork(nn.Module):\n",
        "\n",
        "    def __init__(self, encoder_dim, decoder_dim, attention_dim):\n",
        "    \n",
        "        super(AttentionNetwork, self).__init__()\n",
        "        self.encoder_att = nn.Linear(encoder_dim, attention_dim)  \n",
        "        self.decoder_att = nn.Linear(encoder_dim, attention_dim) \n",
        "        self.full_att = nn.Linear(attention_dim, encoder_dim)  \n",
        "        self.relu = nn.ReLU()\n",
        "        self.softmax = nn.Softmax(dim=1)  \n",
        "\n",
        "    def forward(self, encoder_out, decoder_hidden):\n",
        "        att1 = self.encoder_att(encoder_out)  \n",
        "        att2 = self.decoder_att(decoder_hidden)  \n",
        "        att = self.full_att(self.relu(att1 + att2))  \n",
        "        alpha = self.softmax(att)  \n",
        "        attention_weighted_encoding = (encoder_out * alpha) \n",
        "        return attention_weighted_encoding, alpha\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vE3FvaFV3sy_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DecodeAttentionMaps(nn.Module):\n",
        "\n",
        "  def __init__(self, attention_dim, embed_dim, encoder_dim, max_length, vocab_size, dropout):\n",
        "    super(DecodeAttentionMaps, self).__init__()\n",
        "    self.attention_dim=attention_dim\n",
        "    self.embed_dim=embed_dim\n",
        "    self.encoder_dim=encoder_dim\n",
        "    self.max_length=max_length\n",
        "    self.vocab_size=vocab_size\n",
        "    self.dropout=nn.Dropout(dropout)\n",
        "\n",
        "    self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "    self.tanh=nn.Tanh()\n",
        "    self.question_lstm = nn.LSTM(embed_dim, 1024, num_layers=1, batch_first=True)\n",
        "\n",
        "    self.attention=AttentionNetwork(encoder_dim, max_length, attention_dim)\n",
        "    #self.image_linear=nn.Linear(encoder_dim, embed_dim)\n",
        "    #self.embedding, num_embeddings, embedding_dim=create_emb_layer(weights_matrix, True)\n",
        "    self.relu=nn.ReLU()\n",
        "    self.linear1=nn.Linear(1536, 1024)\n",
        "    self.linear2=nn.Linear(1024, encoder_dim)\n",
        "    self.fc=nn.Linear(encoder_dim, 1000)\n",
        "    self.softmax=nn.Softmax(dim=1)\n",
        "    self.sigmoid=nn.Sigmoid()\n",
        "    self.gru = nn.GRU(embed_dim, encoder_dim, num_layers=1, batch_first=True)\n",
        "  \n",
        "  def forward(self, images, questions):\n",
        "    question_embeddings = self.dropout(self.tanh(self.embedding(questions.type(torch.long))))  # (batch_size, question_length, embed_dim)\n",
        "    output, (hidden, cell) = self.question_lstm(question_embeddings)\n",
        "    hidden = hidden.squeeze(0)\n",
        "    concatenated_features = self.dropout(torch.cat((images, hidden), dim=1))\n",
        "    features=self.dropout(self.relu(self.linear1(concatenated_features)))\n",
        "    attention_weighted_encoding = self.softmax(self.linear2(features))\n",
        "    #attention_weighted_images=(alpha*images)\n",
        "    x=F.relu(self.fc(attention_weighted_encoding))\n",
        "    return self.softmax(x)\n",
        "    '''\n",
        "    out, hidden = self.gru(question_embeddings)\n",
        "    hidden=self.sigmoid(self.linear1(hidden))\n",
        "    images=images\n",
        "    i_q_embed=hidden.squeeze(0)*images\n",
        "    #y = torch.sqrt(F.relu(i_q_embed)) - torch.sqrt(F.relu(-i_q_embed))\n",
        "    #y=self.dropout(y)\n",
        "    alpha=self.softmax(i_q_embed)\n",
        "    #y=y/torch.norm(y,p=2,dim=2).unsqueeze(2)\n",
        "    #y=torch.exp(self.linear2(F.relu(self.linear1(y))))\n",
        "\n",
        "    #alpha= y/torch.sum(y,axis=2).unsqueeze(2)\n",
        "    attention_weighted_images=(alpha*images).squeeze(0)\n",
        "    x=F.relu(self.fc(attention_weighted_images))\n",
        "    return self.softmax(x)\n",
        "    #hidden=hidden.squeeze(0)\n",
        "    #attention_weighted_encoding, alpha = self.attention(images.type(torch.float), hidden.type(torch.float))\n",
        "    #x = F.relu(self.fc(attention_weighted_encoding))\n",
        "    #return self.softmax(x)\n",
        "    \n",
        "    '''\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d32byraynQlT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "images=torch.tensor(image_features_train, dtype=torch.float)\n",
        "questions=torch.tensor(questions_train)\n",
        "max_length=questions.size(-1)\n",
        "encoder_dim=images.size(-1)\n",
        "vocab_size=len(word2idx)\n",
        "attention_dim=512\n",
        "embed_dim=300"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8N4K1c0CfRU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model=DecodeAttentionMaps(attention_dim, embed_dim, encoder_dim, max_length, vocab_size, 0.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7w6aCwsf3ek0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "#optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lz_GtsNh3j1X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_accuracy(predictions, labels):\n",
        "  predictions = torch.max(predictions, axis=1)[1]\n",
        "  # print(predictions)\n",
        "  # print(labels)\n",
        "  # print(predictions.size())\n",
        "  # print(labels.size())\n",
        "  ab = torch.abs(predictions-labels)\n",
        "  # print(ab.size())\n",
        "  ab = ab.detach().numpy()\n",
        "  mn = np.minimum(ab, 1)\n",
        "  eq = 1-mn\n",
        "  # eq = 1 - torch.min(torch.abs(predictions-labels), 1)\n",
        "  correct = np.sum(eq)\n",
        "  # print(correct)\n",
        "  total = eq.shape[0]\n",
        "  return correct, total"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuuJTtb93pdA",
        "colab_type": "code",
        "outputId": "c9641661-0bc6-4944-e0fc-634b66375ff0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "from torch.utils import data\n",
        "tensor_x = torch.tensor(image_features_train, dtype=torch.float)\n",
        "tensor_y = torch.tensor(questions_train)\n",
        "tensor_z = torch.Tensor(answers_train).flatten()\n",
        "tensor_z = tensor_z.type(torch.long)\n",
        "print(tensor_x.size())\n",
        "print(tensor_y.size())\n",
        "print(tensor_z.size())\n",
        "print(tensor_x.dtype)\n",
        "print(tensor_y.dtype)\n",
        "print(tensor_z.dtype)\n",
        "trainset = data.TensorDataset(tensor_x,tensor_y,tensor_z)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=1000, shuffle=True)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([4269, 512])\n",
            "torch.Size([4269, 25])\n",
            "torch.Size([4269])\n",
            "torch.float32\n",
            "torch.float64\n",
            "torch.int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ViqraYS3yn_",
        "colab_type": "code",
        "outputId": "4b91280e-468e-4a7f-ca3a-0ac48abc0597",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "from torch.utils import data\n",
        "tensor_x = torch.tensor(image_features_val,dtype=torch.float)\n",
        "tensor_y = torch.tensor(questions_val)\n",
        "tensor_z = torch.Tensor(answers_val).flatten()\n",
        "tensor_z = tensor_z.type(torch.long)\n",
        "print(tensor_x.size())\n",
        "print(tensor_y.size())\n",
        "print(tensor_z.size())\n",
        "print(tensor_x.dtype)\n",
        "print(tensor_y.dtype)\n",
        "print(tensor_z.dtype)\n",
        "valset = data.TensorDataset(tensor_x,tensor_y,tensor_z)\n",
        "valloader = torch.utils.data.DataLoader(valset, batch_size=1000, shuffle=True)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([837, 512])\n",
            "torch.Size([837, 25])\n",
            "torch.Size([837])\n",
            "torch.float32\n",
            "torch.float64\n",
            "torch.int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCpxTcc7Lxj9",
        "colab_type": "code",
        "outputId": "2fbcd39f-d0ef-4def-dc8c-bb8ba5117e19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "import matplotlib.pyplot as plt \n",
        "import torch.nn.functional as F\n",
        "train_loss=[]\n",
        "val_loss=[]\n",
        "\n",
        "for epoch in range(60):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    total_loss = 0.0\n",
        "    model.train()\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, questions, labels = data\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "        # forward + backward + optimize\n",
        "        outputs = model(inputs, questions)\n",
        "        batch_correct, batch_total = get_accuracy(outputs, labels)\n",
        "        correct += batch_correct\n",
        "        total += batch_total\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        # if i % 1 == 0:    # print every 2000 mini-batches\n",
        "        #     print('[%d, %5d] loss: %.3f' %\n",
        "        #           (epoch + 1, i + 1, running_loss / 2000))\n",
        "        #     running_loss = 0.0\n",
        "        total_loss += running_loss\n",
        "        running_loss = 0.0\n",
        "\n",
        "    val_correct = 0\n",
        "    val_total = 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      for i, data in enumerate(valloader, 0):\n",
        "          # get the inputs; data is a list of [inputs, labels]\n",
        "          inputs, questions, labels = data\n",
        "          # forward + backward + optimize\n",
        "          outputs = model(inputs, questions)\n",
        "          batch_correct, batch_total = get_accuracy(outputs, labels)\n",
        "          val_correct += batch_correct\n",
        "          val_total += batch_total\n",
        "          \n",
        "    print(\"Epoch: \",epoch,\" Loss: \",total_loss,\" Train-Accuracy: \", correct/total,\" Val-Accuracy: \",val_correct/val_total)\n",
        "  \n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:  0  Loss:  34.538620948791504  Train-Accuracy:  0.02506441789646287  Val-Accuracy:  0.03225806451612903\n",
            "Epoch:  1  Loss:  34.538557052612305  Train-Accuracy:  0.030217849613492623  Val-Accuracy:  0.03225806451612903\n",
            "Epoch:  2  Loss:  34.538429260253906  Train-Accuracy:  0.030217849613492623  Val-Accuracy:  0.03225806451612903\n",
            "Epoch:  3  Loss:  34.5381383895874  Train-Accuracy:  0.030217849613492623  Val-Accuracy:  0.03225806451612903\n",
            "Epoch:  4  Loss:  34.537734031677246  Train-Accuracy:  0.030217849613492623  Val-Accuracy:  0.03225806451612903\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0n8T2ZTUW88e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = 0.0001"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZwQPwe1NSMX",
        "colab_type": "code",
        "outputId": "d3979aa7-6a94-4cca-cd87-d57157e03287",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "for epoch in range(17):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    total_loss = 0.0\n",
        "    model.train()\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, questions, labels = data\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "        # forward + backward + optimize\n",
        "        outputs = model(inputs, questions)\n",
        "        batch_correct, batch_total = get_accuracy(outputs, labels)\n",
        "        correct += batch_correct\n",
        "        total += batch_total\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        # if i % 1 == 0:    # print every 2000 mini-batches\n",
        "        #     print('[%d, %5d] loss: %.3f' %\n",
        "        #           (epoch + 1, i + 1, running_loss / 2000))\n",
        "        #     running_loss = 0.0\n",
        "        total_loss += running_loss\n",
        "        running_loss = 0.0\n",
        "\n",
        "    val_correct = 0\n",
        "    val_total = 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      for i, data in enumerate(valloader, 0):\n",
        "          # get the inputs; data is a list of [inputs, labels]\n",
        "          inputs, questions, labels = data\n",
        "          # forward + backward + optimize\n",
        "          outputs = model(inputs, questions)\n",
        "          batch_correct, batch_total = get_accuracy(outputs, labels)\n",
        "          val_correct += batch_correct\n",
        "          val_total += batch_total\n",
        "          \n",
        "    print(\"Epoch: \",epoch,\" Loss: \",total_loss,\" Train-Accuracy: \", correct/total,\" Val-Accuracy: \",val_correct/val_total)\n",
        "  \n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:  0  Loss:  34.53840446472168  Train-Accuracy:  0.21878660107753573  Val-Accuracy:  0.1911589008363202\n",
            "Epoch:  1  Loss:  34.53840446472168  Train-Accuracy:  0.22019208245490748  Val-Accuracy:  0.1911589008363202\n",
            "Epoch:  2  Loss:  34.538405895233154  Train-Accuracy:  0.22019208245490748  Val-Accuracy:  0.1911589008363202\n",
            "Epoch:  3  Loss:  34.538392066955566  Train-Accuracy:  0.22089482314359335  Val-Accuracy:  0.1911589008363202\n",
            "Epoch:  4  Loss:  34.53838777542114  Train-Accuracy:  0.22112907003982196  Val-Accuracy:  0.19474313022700118\n",
            "Epoch:  5  Loss:  34.538395404815674  Train-Accuracy:  0.2213633169360506  Val-Accuracy:  0.19474313022700118\n",
            "Epoch:  6  Loss:  34.538389682769775  Train-Accuracy:  0.2213633169360506  Val-Accuracy:  0.1959378733572282\n",
            "Epoch:  7  Loss:  34.53839445114136  Train-Accuracy:  0.22183181072850786  Val-Accuracy:  0.1959378733572282\n",
            "Epoch:  8  Loss:  34.53838300704956  Train-Accuracy:  0.22159756383227922  Val-Accuracy:  0.1959378733572282\n",
            "Epoch:  9  Loss:  34.538389682769775  Train-Accuracy:  0.22183181072850786  Val-Accuracy:  0.1959378733572282\n",
            "Epoch:  10  Loss:  34.53838491439819  Train-Accuracy:  0.22206605762473647  Val-Accuracy:  0.1959378733572282\n",
            "Epoch:  11  Loss:  34.53836917877197  Train-Accuracy:  0.22206605762473647  Val-Accuracy:  0.1971326164874552\n",
            "Epoch:  12  Loss:  34.53837823867798  Train-Accuracy:  0.22206605762473647  Val-Accuracy:  0.1971326164874552\n",
            "Epoch:  13  Loss:  34.53836488723755  Train-Accuracy:  0.2223003045209651  Val-Accuracy:  0.1971326164874552\n",
            "Epoch:  14  Loss:  34.538360595703125  Train-Accuracy:  0.2223003045209651  Val-Accuracy:  0.1971326164874552\n",
            "Epoch:  15  Loss:  34.53835105895996  Train-Accuracy:  0.2223003045209651  Val-Accuracy:  0.1971326164874552\n",
            "Epoch:  16  Loss:  34.53833627700806  Train-Accuracy:  0.2223003045209651  Val-Accuracy:  0.1971326164874552\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YKx5wI0YMeZ",
        "colab_type": "code",
        "outputId": "44898f2f-6c39-4c18-8243-26d716d27518",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 698
        }
      },
      "source": [
        "for epoch in range(34):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    total_loss = 0.0\n",
        "    model.train()\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, questions, labels = data\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "        # forward + backward + optimize\n",
        "        outputs = model(inputs, questions)\n",
        "        batch_correct, batch_total = get_accuracy(outputs, labels)\n",
        "        correct += batch_correct\n",
        "        total += batch_total\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        # if i % 1 == 0:    # print every 2000 mini-batches\n",
        "        #     print('[%d, %5d] loss: %.3f' %\n",
        "        #           (epoch + 1, i + 1, running_loss / 2000))\n",
        "        #     running_loss = 0.0\n",
        "        total_loss += running_loss\n",
        "        running_loss = 0.0\n",
        "\n",
        "    val_correct = 0\n",
        "    val_total = 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      for i, data in enumerate(valloader, 0):\n",
        "          # get the inputs; data is a list of [inputs, labels]\n",
        "          inputs, questions, labels = data\n",
        "          # forward + backward + optimize\n",
        "          outputs = model(inputs, questions)\n",
        "          batch_correct, batch_total = get_accuracy(outputs, labels)\n",
        "          val_correct += batch_correct\n",
        "          val_total += batch_total\n",
        "          \n",
        "    print(\"Epoch: \",epoch,\" Loss: \",total_loss,\" Train-Accuracy: \", correct/total,\" Val-Accuracy: \",val_correct/val_total)\n",
        "  \n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:  0  Loss:  34.538328647613525  Train-Accuracy:  0.2223003045209651  Val-Accuracy:  0.1971326164874552\n",
            "Epoch:  1  Loss:  34.53831624984741  Train-Accuracy:  0.2223003045209651  Val-Accuracy:  0.1971326164874552\n",
            "Epoch:  2  Loss:  34.53829526901245  Train-Accuracy:  0.2223003045209651  Val-Accuracy:  0.1971326164874552\n",
            "Epoch:  3  Loss:  34.53827142715454  Train-Accuracy:  0.2223003045209651  Val-Accuracy:  0.1971326164874552\n",
            "Epoch:  4  Loss:  34.53825855255127  Train-Accuracy:  0.2223003045209651  Val-Accuracy:  0.1971326164874552\n",
            "Epoch:  5  Loss:  34.53824853897095  Train-Accuracy:  0.2223003045209651  Val-Accuracy:  0.1971326164874552\n",
            "Epoch:  6  Loss:  34.53822469711304  Train-Accuracy:  0.2223003045209651  Val-Accuracy:  0.1971326164874552\n",
            "Epoch:  7  Loss:  34.538185119628906  Train-Accuracy:  0.2223003045209651  Val-Accuracy:  0.1971326164874552\n",
            "Epoch:  8  Loss:  34.53818464279175  Train-Accuracy:  0.22206605762473647  Val-Accuracy:  0.1971326164874552\n",
            "Epoch:  9  Loss:  34.53815460205078  Train-Accuracy:  0.2223003045209651  Val-Accuracy:  0.1971326164874552\n",
            "Epoch:  10  Loss:  34.53811073303223  Train-Accuracy:  0.2223003045209651  Val-Accuracy:  0.1971326164874552\n",
            "Epoch:  11  Loss:  34.53809452056885  Train-Accuracy:  0.21902084797376434  Val-Accuracy:  0.1935483870967742\n",
            "Epoch:  12  Loss:  34.53803873062134  Train-Accuracy:  0.2157413914265636  Val-Accuracy:  0.1911589008363202\n",
            "Epoch:  13  Loss:  34.538010597229004  Train-Accuracy:  0.20777699695479035  Val-Accuracy:  0.18040621266427717\n",
            "Epoch:  14  Loss:  34.537962436676025  Train-Accuracy:  0.19700163972827361  Val-Accuracy:  0.16965352449223417\n",
            "Epoch:  15  Loss:  34.537922859191895  Train-Accuracy:  0.1885687514640431  Val-Accuracy:  0.16487455197132617\n",
            "Epoch:  16  Loss:  34.53790330886841  Train-Accuracy:  0.1820098383696416  Val-Accuracy:  0.16129032258064516\n",
            "Epoch:  17  Loss:  34.53786611557007  Train-Accuracy:  0.17943312251112672  Val-Accuracy:  0.16129032258064516\n",
            "Epoch:  18  Loss:  34.53783941268921  Train-Accuracy:  0.17755914734129774  Val-Accuracy:  0.15890083632019117\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-122-6ed174132f20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_total\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKuhrugRYu0e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}